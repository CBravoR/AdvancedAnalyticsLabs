{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CBravoR/AdvancedAnalyticsLabs/blob/master/notebooks/python/Lab_Explainability_and_SHAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f90c0b-262c-4ac8-99f1-9f91dcb5708d",
      "metadata": {
        "id": "83f90c0b-262c-4ac8-99f1-9f91dcb5708d"
      },
      "source": [
        "# Lab Week 11: SHAP Values and Explainability for non-linear models\n",
        "\n",
        "In this lab we will study how to make complex model more explainable. This is just but a tiny part of what transparency and interpretability actually are, so the topics covered here must be consider a necessary, but not sufficient, step in understanding complex models.\n",
        "\n",
        "Remember: the onus is on the modeller to prove that ML is fair and transparent. This should always be a concern when you are deploying models that affect individuals (i.e. almost always).\n",
        "\n",
        "We will develop an XGB model and then compare traditional measures of statistical importance against modern Shapley Value approaches. We will use the [```shap```](https://shap.readthedocs.io/en/latest/overviews.html) package that implements the methods seen in the lectures.\n",
        "\n",
        "Let's start by training an XGB model. For this we will use the well-known [German Credit dataset](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)), consisting of loans given in the 90s."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ebb591-4483-4e20-a6bc-1755f88b5adb",
      "metadata": {
        "id": "b1ebb591-4483-4e20-a6bc-1755f88b5adb"
      },
      "source": [
        "## XGB model\n",
        "\n",
        "We will train an XGB model. Let's import the data first."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install SHAP if needed\n",
        "!pip install shap"
      ],
      "metadata": {
        "id": "jpedlZSVJFh0"
      },
      "id": "jpedlZSVJFh0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f75b8790-8b7f-42dd-af74-054f294825f3",
      "metadata": {
        "id": "f75b8790-8b7f-42dd-af74-054f294825f3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downgrade gdown due to bug\n",
        "!pip install gdown==v4.6.3"
      ],
      "metadata": {
        "id": "x48jih6DpPZX"
      },
      "id": "x48jih6DpPZX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0117cccf-7f2c-4809-99db-4b6525dd5da2",
      "metadata": {
        "id": "0117cccf-7f2c-4809-99db-4b6525dd5da2"
      },
      "outputs": [],
      "source": [
        "# Download the data if necessary\n",
        "!gdown https://drive.google.com/uc?id=157sNUB1jhD84PyQ-2tMb6MJ9pGb7jeEr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset\n",
        "GCData = pd.read_excel('GermanCredit.xlsx')\n",
        "GCData.head()"
      ],
      "metadata": {
        "id": "QAh7rQ3lhen6"
      },
      "id": "QAh7rQ3lhen6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has mostly categorical features. While [XGB does have support for categorical variables directly](https://xgboost.readthedocs.io/en/latest/tutorials/categorical.html), its interface with the Shap software does not, so we will first transform these into dummy variables."
      ],
      "metadata": {
        "id": "_FntUQxVJ_p-"
      },
      "id": "_FntUQxVJ_p-"
    },
    {
      "cell_type": "code",
      "source": [
        "GCData.dtypes"
      ],
      "metadata": {
        "id": "AKzzdluO3oOE"
      },
      "id": "AKzzdluO3oOE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns\n",
        "columnsToBin = ['CheckingStatus', 'CreditHistory', 'LoanPurpose', 'Savings',\n",
        "                'Employment', 'OtherDebts', 'Property', 'OtherLoans',\n",
        "                'Housing',  'Job', 'Telephone', 'Foreign']\n",
        "\n",
        "# Binarize\n",
        "GCData = pd.get_dummies(GCData, columns = columnsToBin, drop_first=True)\n",
        "GCData.head()"
      ],
      "metadata": {
        "id": "LXJh0r2fJqtK"
      },
      "id": "LXJh0r2fJqtK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a fully numerical dataset, we can train our model. We remove the 'DemData' from the train and test as it is normally not legal to use for credit risk models."
      ],
      "metadata": {
        "id": "kQcMETGx0Nti"
      },
      "id": "kQcMETGx0Nti"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(GCData[GCData.columns[~GCData.columns.isin(['Default', 'DemData'])]], # All columns but the last\n",
        "                                                    GCData['Default'], # target\n",
        "                                                    test_size=0.3, # Size of test set\n",
        "                                                    stratify=GCData['Default'], #stratify\n",
        "                                                    random_state=0 #random seed\n",
        "                                                    )"
      ],
      "metadata": {
        "id": "eBrrCRlL1k_A"
      },
      "id": "eBrrCRlL1k_A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the XGB model\n",
        "model = XGBClassifier(max_depth=3,                 # Depth of each tree\n",
        "                            learning_rate=0.1,            # How much to shrink error in each subsequent training. Trade-off with no. estimators.\n",
        "                            n_estimators=100,             # How many trees to use, the more the better, but decrease learning rate if many used.\n",
        "                            verbosity=1,                  # If to show more errors or not.\n",
        "                            objective='binary:logistic',  # Type of target variable.\n",
        "                            booster='gbtree',             # What to boost. Trees in this case.\n",
        "                            n_jobs=-1,                     # Parallel jobs to run. Set your processor number.\n",
        "                            gamma=0.001,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree. (Controls growth!)\n",
        "                            subsample=0.632,              # Subsample ratio. Can set lower\n",
        "                            colsample_bytree=1,           # Subsample ratio of columns when constructing each tree.\n",
        "                            colsample_bylevel=1,          # Subsample ratio of columns when constructing each level. 0.33 is similar to random forest.\n",
        "                            colsample_bynode=1,           # Subsample ratio of columns when constructing each split.\n",
        "                            scale_pos_weight=700.0/300.0,           # Balancing of positive and negative weights.\n",
        "                            base_score=0.5,               # Global bias. Set to average of the target rate.\n",
        "                            random_state=0,        # Seed\n",
        "                            )\n"
      ],
      "metadata": {
        "id": "EeAB7dTEyRBd"
      },
      "id": "EeAB7dTEyRBd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the grid search\n",
        "param_grid = dict({'n_estimators': [250, 300, 350],\n",
        "                   'max_depth': [4, 5, 6],\n",
        "                 'learning_rate' : [0.001, 0.01, 0.1]\n",
        "                  })\n",
        "\n",
        "# Define the crossvalidation object\n",
        "cv_object = StratifiedKFold(n_splits=3)\n",
        "\n",
        "# Define grid search object\n",
        "GridXGB = GridSearchCV(model,        # Original XGB.\n",
        "                       param_grid,          # Parameter grid\n",
        "                       cv = cv_object,      # Cross-validation object.\n",
        "                       scoring = 'roc_auc', # How to rank outputs.\n",
        "                       n_jobs = -1,          # Parallel jobs. -1 is \"all you have\"\n",
        "                       refit = True,       # If refit at the end with the best. As we use all data, it works fine. Change to False if using validation sample.\n",
        "                       verbose = 1          # If to show what it is doing.\n",
        "                      )\n",
        "\n",
        "# Train grid search\n",
        "GridXGB.fit(x_train, y_train)\n",
        "\n",
        "# Show best params\n",
        "print(GridXGB.best_params_)"
      ],
      "metadata": {
        "id": "5cPz8jz41QXt"
      },
      "id": "5cPz8jz41QXt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the precision recall curve\n",
        "probTest = GridXGB.predict_proba(x_test)\n",
        "probTest = probTest[:, 1]\n",
        "\n",
        "# Calculate the ROC curve points\n",
        "fpr, tpr, thresholds = roc_curve(y_test,\n",
        "                                 probTest)\n",
        "\n",
        "# Save the AUC in a variable to display it. Round it first\n",
        "auc = np.round(roc_auc_score(y_true = y_test,\n",
        "                             y_score = probTest),\n",
        "               decimals = 3)\n",
        "\n",
        "# Create and show the plot\n",
        "plt.plot(fpr,tpr,label=\"AUC - XGBoosting = \" + str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uonl83VG5a9P"
      },
      "id": "uonl83VG5a9P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a fully trained XGB models we can study the impact of the variables using Shapley Values."
      ],
      "metadata": {
        "id": "-xPcNGev28uR"
      },
      "id": "-xPcNGev28uR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall impact\n",
        "\n",
        "The first step is to obtain the global importance. The variable_importance property in the XGB algorithm includes only the data from the gain in Gini. The one derived from Shapley values compares values of cases against each other. Let's study the difference."
      ],
      "metadata": {
        "id": "OCHakZWN4zUy"
      },
      "id": "OCHakZWN4zUy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable importance\n",
        "importances = GridXGB.best_estimator_.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "f, ax = plt.subplots(figsize=(3, 8))\n",
        "plt.title(\"Variable Importance - XGB\")\n",
        "sns.set_color_codes(\"pastel\")\n",
        "sns.barplot(y=[x_train.columns[i] for i in indices],\n",
        "            x=importances[indices],\n",
        "            label=\"Total\", color=\"b\")\n",
        "ax.set(ylabel=\"Variable\",\n",
        "       xlabel=\"Variable Importance (Entropy)\")\n",
        "sns.despine(left=True, bottom=True)"
      ],
      "metadata": {
        "id": "kg1ZetWh3Dl3"
      },
      "id": "kg1ZetWh3Dl3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot consider each importance independently, however **variable importances are additive**, thus you can add the importances from the discrete variables to get a per-variable instead of a per-dummy variable. The same applies to Shap.\n",
        "\n",
        "Shap will calculate the average contribution per variable using its game-theoretic approach (see the lectures). This will necessarily be different than the Gini approach from the XGB operator. The Gini approach aims at average contribution per tree (e.g. at a population level), the Shap one at an average contribution per case.\n",
        "\n",
        "In order to create all the plots in the Shap package, it is first necessary to calculate the Shap contributions. This should be done over a relatively small set as it otherwise can take a long time. We will use the test set for this."
      ],
      "metadata": {
        "id": "fTPrifTO6cEP"
      },
      "id": "fTPrifTO6cEP"
    },
    {
      "cell_type": "code",
      "source": [
        "# the variable importance by mean-shap values\n",
        "explainer = shap.Explainer(GridXGB.best_estimator_)\n",
        "shap_values = explainer(x_test)"
      ],
      "metadata": {
        "id": "lUOu980_5tAb"
      },
      "id": "lUOu980_5tAb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the explainer calculated, we can estimate the impact over all variables. This will average the contributions for each pair of cases."
      ],
      "metadata": {
        "id": "sFSGMNPtThmA"
      },
      "id": "sFSGMNPtThmA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the average importances.\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "d5Dk1BPDTg_R"
      },
      "id": "d5Dk1BPDTg_R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Per case impact\n",
        "\n",
        "The second very useful plot is the waterfall plot that shows the impact of each variable in a specific case. This satisfies the explainability requirements in most legistlations. As the model is non-linear, the impacts can be very different for each person."
      ],
      "metadata": {
        "id": "7H858adpXI7-"
      },
      "id": "7H858adpXI7-"
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.waterfall(shap_values[0])"
      ],
      "metadata": {
        "id": "925U9oRk7Cn-"
      },
      "id": "925U9oRk7Cn-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.waterfall(shap_values[10])"
      ],
      "metadata": {
        "id": "vCy1FNlgXrsg"
      },
      "id": "vCy1FNlgXrsg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An alternative are the force plots, which show the same information in a line. This requires having javascript installed though."
      ],
      "metadata": {
        "id": "YI-jU4ceX7xL"
      },
      "id": "YI-jU4ceX7xL"
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "shap.plots.force(shap_values[0])"
      ],
      "metadata": {
        "id": "bApEWeL37P5w"
      },
      "id": "bApEWeL37P5w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Per variable impact\n",
        "\n",
        "A third way to visualize the impact of variables is by plotting a scatterplot of the Shapley value (i.e. the normalized impact in the prediction) and the value of the variable. This will allow us to see how the prediction varies across the different values, also evidencing non-linearities. The shap package also codes the scatterplot by colour using the most correlated variable.\n",
        "\n",
        "For example, the term function presents a clear non-linear pattern, which is consistent with its most correlated variable: LoanPurpose_A41, also presenting the same (binary) behaviour)."
      ],
      "metadata": {
        "id": "Z9a_8jX4YD5y"
      },
      "id": "Z9a_8jX4YD5y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter\n",
        "shap.plots.scatter(shap_values[:,\"Term\"], color=shap_values)"
      ],
      "metadata": {
        "id": "U6LVgfLT7RJe"
      },
      "id": "U6LVgfLT7RJe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age shows an inverse pattern, but it's most correlated variable does not show the same consistency."
      ],
      "metadata": {
        "id": "1yguLoQgYtbv"
      },
      "id": "1yguLoQgYtbv"
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.scatter(shap_values[:,\"Age\"], color=shap_values)"
      ],
      "metadata": {
        "id": "147Zvng57bnZ"
      },
      "id": "147Zvng57bnZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting it all together\n",
        "\n",
        "A final, and very useful, plot puts together the per variable impact and the per case impact by plotting the Shapley value on the x-axis, the amount of cases with that Shapley value on the distribution plot, and finally using colour coding to represent the value of the variables. This is called a beeswarm plot."
      ],
      "metadata": {
        "id": "FT1MFyK7Y3gC"
      },
      "id": "FT1MFyK7Y3gC"
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.beeswarm(shap_values)"
      ],
      "metadata": {
        "id": "1AlpRPFEZRFD"
      },
      "id": "1AlpRPFEZRFD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now see how each feature behave and how they contribute to the prediction. For example, the binary variable CheckingStatus_A14 has a non-linear  impact, that's consistent across all cases. For a value of 1, it consistently provides a reduction in risk (negative Shapley value) but this reduction varies between approximately -1.5 (very high impact in prediction) to less than 0.5. (moderate impact). For a value of 0, the prediction impact is moderate and much more concentrated.\n",
        "\n",
        "Analyze the rest!"
      ],
      "metadata": {
        "id": "vFFXKM03ZXU7"
      },
      "id": "vFFXKM03ZXU7"
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values)"
      ],
      "metadata": {
        "id": "DThLGZHam_Fz"
      },
      "id": "DThLGZHam_Fz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confounding\n",
        "\n",
        "Studying confounding is much more difficult. Confounding is the problem of identifying if a variable is caused by an alternative factor. A consequence of confounding is that it can add discrimination by undersirable variables or discriminate against specific groups. There is no standardized test to identify confounding. What is necessary is to measure the relation of variables that we do not want to discriminate by checking them and studying their relation.\n",
        "\n",
        "A good strategy is to run a pairplot of all predictive variables and use the variable we want to control by as hue. With this:\n",
        "\n",
        "- For discrete controls, we can see if the distributions between different strata of the variable (as determined by the control variable) present different distributions. If they do, then that variable is also discriminating by the control and needs to be treated to eliminate that impact. For example, segmenting can be used to eliminate the differences in between the distributions, or use one of the continuous variable methods below.\n",
        "\n",
        "- For continuous controls, correlations can be seen to determine the same effect. In this case, segmenting will most likely not be helpful and removing the offending variable from the model should be considered, or adding an interaction term (Variable * Control) and then using, e.g., the average of the prediction across all values of the control.\n",
        "\n",
        "Let's study our dataset."
      ],
      "metadata": {
        "id": "74iQCAED70Bo"
      },
      "id": "74iQCAED70Bo"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(GCData[['Age', 'Term', 'LoanAmt', 'DemData']], hue='DemData')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XEVHi_6L7pax"
      },
      "id": "XEVHi_6L7pax",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, Age shows different distributions depending on the values of the demographic segmentation. This means the model, by using Age, is discriminating also by the factors, so if this is not desirable, a control method should be use such segmenting,  interacting and averaging between all cases, or removing age  from the model.\n",
        "\n",
        "Fair models are a nascent area of research, so these methods and recommendations are bound to evolve in the coming years. Always be mindful of what you are doing and who your models may affect!"
      ],
      "metadata": {
        "id": "UwxQNwWGcl-4"
      },
      "id": "UwxQNwWGcl-4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}