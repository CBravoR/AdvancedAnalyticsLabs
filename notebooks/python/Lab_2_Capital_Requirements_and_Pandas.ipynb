{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2 - Capital Requirements and Pandas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CBravoR/AdvancedAnalyticsLabs/blob/master/notebooks/python/Lab_2_Capital_Requirements_and_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cthgu5dSzuJ-"
      },
      "source": [
        "# Capital requirements and Pandas\n",
        "\n",
        "In this lab, we'll implement the formulas for capital requirements, and we will apply it to a complete dataset. For this goal we will use the excellent [```pandas```](https://pandas.pydata.org/) package, which allows for data handling in general.\n",
        "\n",
        "***Important self-study: Go through the [10 minutes to Pandas tutorial](https://pandas.pydata.org/docs/user_guide/10min.html).***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg7bCCwd0bHd"
      },
      "source": [
        "## Reading the data\n",
        "\n",
        "For this exercise we will read a dataset from credit scoring. I previously uploaded the data to Google, and it is available at https://docs.google.com/spreadsheets/d/1Am74y2ZVQ6dRFYVZUv_VoyP-OTS8BM4x0svifHQvtNc/export?gid=819627738&format=csv\n",
        "\n",
        "The dataset (called **Bankloan**, from IBM) has a set of 1,000 loans with default information. It includes the following variables:\n",
        "\n",
        "- Customer: ID, or unique label, of the borrower (NOT predictive).\n",
        "- Age: Age of the borrower in years.\n",
        "- Education: Maximum education level the borrower reached.\n",
        "1: Complete primary. 2: Completed Secondary. 3: Incomplete Higher Ed. 4: Complete Higher Ed. 5: With postgraduate studies (complete MSc or PhD).\n",
        "- Employ: Years at current job.\n",
        "- Address: Years at current address.\n",
        "- Income: Income in ‘000s USD.\n",
        "- Leverage: Debt/Income Ratio.\n",
        "- CredDebt: Credit card standing debt.\n",
        "- OthDebt: Other debt in ‘000s USD.\n",
        "- MonthlyLoad: Monthly percentage from salary used to repay debts.\n",
        "- Default: 1 If default has occurred, 0 if not (Target variable).\n",
        "- PD: The calibrated probability of default of the loan.\n",
        "- LGD: The estimated LGD for the loan.\n",
        "- Outstanding: EAD.\n",
        "\n",
        "The goal is to construct a model to predict whether the loan is going to default or not. We will use this dataset for the next few labs.\n",
        "\n",
        "To actually get the data, we could:\n",
        "\n",
        "- Download the file following the link.\n",
        "- Upload the file to our Google Drive\n",
        "- Connect the google drive to our own Colab session\n",
        "- Import the file\n",
        "\n",
        "This is... tedious. The second alternative is to simply download the file from the web directly to our session. This can be done with Linux's command ```gdown```. This is NOT a Python command, but an operative system command, thus we need to invoke it with the prefix ```!``` which means \"run this in the operative system\".\n",
        "\n",
        "The command is\n",
        "\n",
        "```\n",
        "gdown Google_Path\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp2he3jP0acB"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1lyEd01JaoVbL1mbgn-wr3YvLmURAgQ8B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxZrUiDLMye6"
      },
      "source": [
        "Note that it downloads it to ```/content/FILENAME```. To check what we  downloaded we can use the ```head``` OS command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO8ZUMz1Mzf0"
      },
      "source": [
        "!head /content/bankloan_scored_nodefault.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4kq7ZXkMXOE"
      },
      "source": [
        "## Pandas\n",
        "\n",
        "Now we will use Pandas to read the CSV file. The  function to do so is [```read_csv```](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). We will store the results in a variable named ```loan_data```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-P17DdYM-40"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "bankloan_data = pd.read_csv('/content/bankloan_scored_nodefault.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PyIJPx0NED9"
      },
      "source": [
        "Now we can start exploring the data. First, a list of the variables and its types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjY06WDPNFWN"
      },
      "source": [
        "bankloan_data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPZ8Ol9SNHrR"
      },
      "source": [
        "Int64 are integers, float64 are decimals, and object means a general type. In this case text.\n",
        "\n",
        "Using the ```describe``` function we can get summary statistics of the numerical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uluQVPhLNK2q"
      },
      "source": [
        "bankloan_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g13R0-vQNO_a"
      },
      "source": [
        "To get an idea of the different distributions of the data, we can plot the histograms of the variables. First, we import the graphic environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1sqyXdANQDa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_opsrRVNTD2"
      },
      "source": [
        "histograms = bankloan_data.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAj905Asj8e4"
      },
      "source": [
        "bankloan_data.loc[:, 'Age'].iloc[1:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxdYS_3WNbEV"
      },
      "source": [
        "However, there is a far more powerful package for visualizing data, that uses Pandas as its backend: [seaborn](https://seaborn.pydata.org/introduction.html). Let's visualize the dataset using this tool."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvoO_TfRNcSS"
      },
      "source": [
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdiV2Gc9NeAG"
      },
      "source": [
        "sns.set(color_codes=True)\n",
        "sns.pairplot(bankloan_data, hue = 'Default')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWK-4UGbN25y"
      },
      "source": [
        "In a future lab we will focus on data cleaning and what we should look for in this dataset, but for now we can properly calculate the Basel Capital Requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpaRoXKD3x3b"
      },
      "source": [
        "## Basel III Capital Requirements\n",
        "\n",
        "Recalling the last lecture, the equation for the capital requirement of any operation is:\n",
        "\n",
        "$$\n",
        "K = LGD \\cdot \\left\\{ N\\left( \\sqrt{\\frac{1}{1-R}} \\cdot N^{-1}(PD) + \\sqrt{\\frac{R}{1-R}} \\cdot N^{-1}(0.999) \\right) - PD \\right\\} \\left( \\frac{1 + (M - 2.5)b}{1 - 1.5b}\\right)\n",
        "$$\n",
        "\n",
        "The values of $b$ and $M$ will be variable for bonds, but for retail and mortgages the maturity is fixed at 1, and the b term dissapears. The correlations are given by the regulation:\n",
        "\n",
        "- Mortgages: $R = 0.15$\n",
        "- Revolving: $R = 0.04$\n",
        "- Other retail: $R = 0.03 \\left( \\frac{1 - e^{-35PD}}{1 - e^{-35}} \\right) + 0.16 \\left( 1 - \\frac{1 - e^{-35PD}}{1 - e^{-35}} \\right)$\n",
        "- Corporate and sovereign exposures $ R = 0.12 \\left( \\frac{1 - e^{-50PD}}{1 - e^{-50}} \\right) + 0.24 \\left( 1 - \\frac{1 - e^{-50PD}}{1 - e^{-50}} \\right)$\n",
        "\n",
        "With this we can calculate the capital requirements and the Risk Weighted Assets (RWA) for this portfolio. Let's start implementing the capital requirement function. Note that we require the cumulative normal distribution  and its inverse functions. For this we will use numpy's sister package [```scipy```](https://scipy.org/) which includes all (traditional) statistical models and quantities for classic stats (not analytics!) in its subpackage [```stats```](https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html).\n",
        "\n",
        "Within the package stats, we find the statistical distribution we need: [```norm```](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm), the standard normal. Within it, we can call the cumulative function (```norm.cdf```) and the inverse function, ```norm.ppf``` which stands for *[percent point function](https://stackoverflow.com/questions/20626994/how-to-calculate-the-inverse-of-the-normal-cumulative-distribution-function-in-p)*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_fu2Owu9Gtq"
      },
      "source": [
        "def capital_requirement_retail(PD, LGD):\n",
        "  import numpy as np\n",
        "  from scipy.stats import norm\n",
        "  # First part of the equation, lower correlation\n",
        "  R =  0.03 * ( (1 - np.exp(-35 * PD)) / (1 - np.exp(-35)) )\n",
        "  # Second part of the equation, higher correlation \n",
        "  R += 0.16 * (1 - ( (1 - np.exp(-35 * PD)) / (1 - np.exp(-35)) ) )\n",
        "  # Now we can calculate the capital\n",
        "  K = norm.cdf(np.sqrt( (1 - R) ** (-1) ) * norm.ppf(PD) + \n",
        "               np.sqrt( R / (1 - R) ) * norm.ppf(0.999) ) - PD\n",
        "  K *= LGD\n",
        "  return(K) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSNhrhH9BCND"
      },
      "source": [
        "# 50% PD rate and LGD = 0.5\n",
        "print('PD = 0.5 & LGD = 0.5. K = %.3f' % capital_requirement_retail(0.5, 0.5))\n",
        "\n",
        "# PD = 1 and LGD = 1\n",
        "print('PD = 1 & LGD = 1. K = %.3f' % capital_requirement_retail(1, 1))\n",
        "\n",
        "# PD = 1 and LGD = 1\n",
        "print('PD = 0.99 & LGD = 0.99. K = %.3f' % capital_requirement_retail(0.99, 0.99))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywUbvV9EBH2"
      },
      "source": [
        "We can see the capital requirement is a non-linear function of the PD and LGD (**why?**). \n",
        "\n",
        "Let's study the plot for a fixed LGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXczxRiABF5o"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "Nseries = np.arange(0, 1, 0.001)\n",
        "plt.plot(Nseries, capital_requirement_retail(Nseries, 1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO0Eh2g-Ewn7"
      },
      "source": [
        "With this we can now calculate the capital requirement of the portfolio, applying the function to every loan in the dataset. For this we need to use two different functions: the [```apply```](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) function from Pandas, which applies a function to rows or columns from a dataset, and a short [lambda function](https://www.w3schools.com/python/python_lambda.asp). \n",
        "\n",
        "A lambda function is, quite simply, a synonym for another function where you specify some inputs and outputs. In this case, our Basel capital requirement function has the problem it requires only the PD and LGD from the row, but Pandas will cast the function to the whole row. With a lambda function we can just specify which columns it will use, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNbnu-dE3uP"
      },
      "source": [
        "bankloan_data['CapitalReq'] = bankloan_data.apply(lambda x : capital_requirement_retail(x['PD'], x['LGD']), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASqIycM7RvLF"
      },
      "source": [
        "Now we have calculated the capital requirements into a new column of the dataframe, ```CapitalReq```! To see how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxf5cWTVR3jP"
      },
      "source": [
        "sns.distplot(bankloan_data['CapitalReq'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14A51czTSKet"
      },
      "source": [
        "And we can finally calculate the maximum Risk Weighted Asset (RWA) value. Assuming a factor $F = 8\\%$, remember that:\n",
        "\n",
        "$$\n",
        "RWA = \\frac{1}{F} * K * EAD\n",
        "$$\n",
        "\n",
        "in retail lending the Exposure at Default is equal to the outstanding amount, leading to:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StQaz_o5SdP4"
      },
      "source": [
        "RWA = (1 / 0.08) * np.dot(bankloan_data['CapitalReq'], bankloan_data['Outstanding'])\n",
        "RWA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh_dpo2vTtbF"
      },
      "source": [
        "Every bank will have a different factor of the RWA which it must conserve. This will depend on its own characteristics. If, for example, the bank had a 12% requirement, then its regulatory capital would be equal to:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afkmkLclT7tO"
      },
      "source": [
        "RWA = (1 / 0.12) * np.dot(bankloan_data['CapitalReq'], bankloan_data['Outstanding'])\n",
        "\n",
        "\n",
        "# To format money correctly\n",
        "import locale\n",
        "locale.setlocale( locale.LC_ALL, '' )\n",
        "\n",
        "# Display\n",
        "out = locale.currency( RegCap, grouping=True )\n",
        "print('The maximum value for the RWA at a 12% capital requirement is equal to ' + out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H85jCf3ViK1"
      },
      "source": [
        "And that's it! Note that this example is ommitting a few important steps, such as we did not check the PD or LGD lower floors that  are in effect in Basel III and the outstanding amount was given to you. You are now ready to answer the quantitative question for coursework 1!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Q6qWVcGJnF"
      },
      "source": [
        "## Self-Study\n",
        "\n",
        "During the lab we used the ```apply``` function to cast a formula throughout a dataset. This uses only a limited amount of resources. To speed this up, and take advantage of modern machines with more than one core, we can use a multicore approach.\n",
        "\n",
        "This is called **paralelizing**. The idea is to run your apply function using all available cores, as they do not interfere with each other.\n",
        "\n",
        "To do so, read through the tutorial of the package [swifter](https://github.com/jmcarpenter2/swifter). Modify the apply call to include this multicore call, and test the running time. Your code should be much faster. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPfDNs4zG4PA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}